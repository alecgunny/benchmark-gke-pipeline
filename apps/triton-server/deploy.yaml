apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.name }}
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Values.name }}
  progressDeadlineSeconds: 100
  template:
    metadata:
      labels:
        app: {{ .Values.name }}
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: tritonserver
        image: nvcr.io/nvidia/tritonserver:20.11-py3
        env:
        - name: EXTRA_NV_PATHS
          value: /usr/local/nvidia/lib64:/usr/local/nvidia/bin
        command:
        - /bin/bash
        args:
        - -c
        - LD_LIBRARY_PATH="$LD_LIBRARY_PATH:$EXTRA_NV_PATHS" bin/tritonserver --model-repository gs://{{ .Values.repo }} --repository-poll-secs 30
        resources:
          limits:
            nvidia.com/gpu: {{ .Values.gpus }}
            cpu: {{ .Values.vcpus }}
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 8001
          name: grpc
        - containerPort: 8002
          name: metrics
        livenessProbe:
          failureThreshold: 30
          initialDelaySeconds: 100
          periodSeconds: 5
          httpGet:
            path: /v2/health/live
            port: http
        readinessProbe:
          failureThreshold: 30
          initialDelaySeconds: 600
          periodSeconds: 5
          httpGet:
            path: /v2/health/ready
            port: http
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-t4
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Values.name }}
  namespace: default
spec:
  #externalTrafficPolicy: Cluster
  ports:
  - name: http-triton
    port: 8000
    protocol: TCP
    targetPort: 8000
  - name: grpc-triton
    port: 8001
    protocol: TCP
    targetPort: 8001
  - name: metrics-triton
    port: 8002
    protocol: TCP
    targetPort: 8002
  selector:
    app: {{ .Values.name }}
  sessionAffinity: None
  type: LoadBalancer
